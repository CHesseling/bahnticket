{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import codecs\n",
    "import codecs, io\n",
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ansichtsoptionen für Pandas Dataframes\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haltestellendaten der Deutschen Bahn AG / DB Station&Service AG \n",
    "# Quelle: https://data.deutschebahn.com/dataset/data-haltestellen/resource/27ce767b-4d62-4806-8922-908d2cf65f1e\n",
    "# Lizenz:  Creative Commons Attribution 4.0 International (CC BY 4.0)\n",
    "\n",
    "stations = pd.read_csv('D_Bahnhof_2017_09.csv', sep=\";\", decimal=\",\")\n",
    "stations = stations.drop(['DS100', 'IFOPT', 'VERKEHR', 'STATUS'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stations.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle PDFs im Unterverzeichnis 'tickets' in eine Liste laden\n",
    "\n",
    "extension = 'pdf'\n",
    "all_filenames = [i for i in glob.glob('tickets/*.{}'.format(extension))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsen der PDFs\n",
    "\n",
    "list_of_data = []\n",
    "\n",
    "\n",
    "for t in all_filenames:\n",
    "\n",
    "    # PDF öffnen\n",
    "    pdfFileObj = io.open(t, 'rb')\n",
    "    pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "    \n",
    "    # 1 Seite des PDFs öffnen - bei manchen Tickets gibt es mehrere Seiten - Funktion folgt\n",
    "    pageObj = pdfReader.getPage(0)\n",
    "    \n",
    "    # Text extrahieren\n",
    "    text2 = pageObj.extractText()\n",
    "    pdfFileObj.close()\n",
    "    \n",
    "    # Text in einzelne Zeilen  \n",
    "    values = text2.split('\\n');\n",
    "    data = []\n",
    "    try:\n",
    "        # Es gibt verschiedene Ticket-Varianten. Hier wird versucht, die meisten Möglichkeiten abzufangen\n",
    "        # Die Varianten werden mit 1, 2, 3a-c, 4 dargestellt\n",
    "        if values[2].split(' ')[1] == 'Hinfahrt:':\n",
    "            data.append(t.split('\\\\')[1])\n",
    "            data.append(str(values[2].split(': ')[1]))\n",
    "            data.append(values[7])\n",
    "            data.append(values[8])\n",
    "            if values[8][-10:-1] == 'R•ckfahrt':\n",
    "                data.append(values[9].split(' ')[0])\n",
    "                data.append(values[9].split(' ')[2])\n",
    "            else:\n",
    "                data.append(values[10])\n",
    "                data.append(values[11])\n",
    "            data.append(\"1\")\n",
    "        elif values[2].split(' ')[0] == 'G•ltigkeit:':\n",
    "            data.append(t.split('\\\\')[1])\n",
    "            data.append(str((values[3].split(' ')[1][0:10])))\n",
    "            data.append(values[7].split(' ')[0])\n",
    "            data.append(values[7].split(' ')[2])\n",
    "            data.append('-')\n",
    "            data.append('-')\n",
    "            data.append(\"2\")\n",
    "        elif values[2].split(' ')[1] == 'am':\n",
    "            \n",
    "            data.append(t.split('\\\\')[1])\n",
    "            data.append(str((values[2].split(' ')[2])))\n",
    "            data.append(values[5].split(' ')[0])\n",
    "            if values[6][0:3] == 'VIA':\n",
    "                data.append(values[5].split(' ')[2])\n",
    "                variante = \"3a\"\n",
    "            elif values[4][-9:-1] == 'Hinfahrt':\n",
    "                data.append(values[5].split(' ')[2])\n",
    "                variante = \"3b\"\n",
    "            else:\n",
    "                data.append(values[6].split(' ')[1])\n",
    "                variante = \"3c\"\n",
    "            data.append('-')\n",
    "            data.append('-')\n",
    "            data.append(variante)\n",
    "            \n",
    "        elif values2[6].endswith('Hinfahrt:') == True:\n",
    "            data.append(t.split('\\\\')[1])\n",
    "            data.append(values2[3].split(' ')[1][0:10])\n",
    "            data.append('-')\n",
    "            data.append('-')         \n",
    "            data.append('-')\n",
    "            data.append('-') \n",
    "            data.append(\"4\")\n",
    "        #print (filename,datum, von1, nach1, von2, nach2)\n",
    "        #print (filename, datum, von1, nach1, von2, nach2, variante)\n",
    "        list_of_data.append(data)\n",
    "    \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeugen des Dataframes\n",
    "\n",
    "df = pd.DataFrame(list_of_data, columns = ['Datei','Datum', 'Von_1', 'Nach_1', 'Von_2', 'Nach_2', 'Variante'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Texte sind etwas \"messy\" und enthalten falsche Umlaute.\n",
    "# Hier wird versucht, ein wenig zu \"putzen\"\n",
    "\n",
    "df = df.replace({'\\+City': ''}, regex=True)\n",
    "df = df.replace({'\\+City, mit IC/ECR•ckfahrt:': ''}, regex=True) \n",
    "df = df.replace({'mit IC\\/ECR•ckfahrt::': ''}, regex=True)\n",
    "df = df.replace({'mit ICER•ckfahrt:': ''}, regex=True)\n",
    "df = df.replace({'mit IC\\/ECR•ckfahrt:': ''}, regex=True)\n",
    "df = df.replace({'K‡ln': 'Köln'}, regex=True)\n",
    "df = df.replace({'K•ln': 'Köln'}, regex=True)\n",
    "df = df.replace({'M•nster': 'Münster'}, regex=True)\n",
    "df = df.replace({'\\†': 'ü'}, regex=True)\n",
    "df = df.replace({'K…ln': 'Köln'}, regex=True)\n",
    "df = df.replace({'K—ln': 'Köln'}, regex=True)\n",
    "df = df.replace({'\\,': ''}, regex=True)\n",
    "df = df.replace({'über:': ''}, regex=True)\n",
    "df['Von_1'] = df['Von_1'].str.strip()\n",
    "df['Nach_1'] = df['Nach_1'].str.strip()\n",
    "df['Von_2'] = df['Von_2'].str.strip()\n",
    "df['Nach_2'] = df['Nach_2'].str.strip()\n",
    "df['Von_1_bhf'] = df['Von_1'] + ' Hbf'\n",
    "df['Nach_1_bhf'] = df['Nach_1'] + ' Hbf'\n",
    "df['Von_2_bhf'] = df['Von_2'] + ' Hbf'\n",
    "df['Nach_2_bhf'] = df['Nach_2'] + ' Hbf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion, um den Bahnhof mit dem ähnlichen Namen aus der Stationsliste zu finden\n",
    "\n",
    "def fuzzy_merge(df_1, df_2, key1, key2, threshold=90, limit=2):\n",
    "\n",
    "    s = df_2[key2].tolist()\n",
    "\n",
    "    m = df_1[key1].apply(lambda x: process.extract(x, s, limit=limit))    \n",
    "    df_1['matches'] = m\n",
    "\n",
    "    m2 = df_1['matches'].apply(lambda x: ', '.join([i[0] for i in x if i[1] >= threshold]))\n",
    "    \n",
    "    col = key1 + '_matches'\n",
    "    df_1[col] = m2\n",
    "\n",
    "    return df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abgleichen der Haltestellen mit der Stationsliste\n",
    "\n",
    "df = fuzzy_merge(df, stations, 'Von_1_bhf', 'NAME', threshold=80)\n",
    "\n",
    "df = fuzzy_merge(df, stations, 'Nach_1_bhf', 'NAME', threshold=80)\n",
    "\n",
    "df['Von_1_bhf_matches'] = df['Von_1_bhf_matches'].str.split(\",\", n = 1, expand = True)[0]\n",
    "\n",
    "df['Nach_1_bhf_matches'] = df['Nach_1_bhf_matches'].str.split(\",\", n = 1, expand = True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lat/Long - Daten aus dem Bahn-Datensatz verknüpfen \n",
    "# Erst den VON-Bahnhof\n",
    "df = df.merge(stations, left_on='Von_1_bhf', right_on='NAME', how='outer')\n",
    "\n",
    "# Spalten umbenennen\n",
    "df.rename(columns={'LAENGE': 'Von_1_bhf_laenge', 'BREITE': 'Von_1_bhf_breite', 'EVA_NR': 'Von_1_bhf_EVA_NR'}, inplace=True)\n",
    "\n",
    "# Dann NACH-Bahnhof\n",
    "df = df.merge(stations, left_on='Nach_1_bhf', right_on='NAME', how='outer')\n",
    "df.rename(columns={'LAENGE': 'Nach_1_bhf_laenge', 'BREITE': 'Nach_1_bhf_breite', 'EVA_NR': 'Nach_1_bhf_EVA_NR'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Lat/Long Berechnung über Nominatim\n",
    "\n",
    "#locator = Nominatim(user_agent=\"bahnticket_auswertung\")\n",
    "\n",
    "#from geopy.extra.rate_limiter import RateLimiter\n",
    "#geocode = RateLimiter(locator.geocode, min_delay_seconds=3)\n",
    "#df['Von_1_ltlg'] = df['Von_1_bhf'].apply(geocode)\n",
    "#df['Von_1_point'] = df['Von_1_ltlg'].apply(lambda loc: tuple(loc.point) if loc else None)\n",
    "#df['Nach_1_ltlg'] = df['Nach_1_bhf'].apply(geocode)\n",
    "#df['Nach_1_point'] = df['Nach_1_ltlg'].apply(lambda loc: tuple(loc.point) if loc else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ist Rückfahrt gleich Hinfahrt?\n",
    "\n",
    "df['rueckfahrt_gleich'] = df['Von_1'] == df['Nach_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Leere und fehlerhafte Zeilen löschen\n",
    "\n",
    "df = df.dropna(thresh=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lat/Long der Bahnhöfe in eine URL-Spalte bauen\n",
    "\n",
    "df['url'] = 'https://brouter.damsy.net/api/brouter?lonlats=' + df['Von_1_bhf_laenge'].map(str) + ',' + df['Von_1_bhf_breite'].map(str) + '|' + df['Nach_1_bhf_laenge'].map(str) + ',' + df['Nach_1_bhf_breite'].map(str) + '&profile=rail&alternativeidx=0&format=geojson' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Aufrufen der Distanzmessungs-API\n",
    "# Bitte die Anzahl der Anfragen begrenzen!\n",
    "\n",
    "def entfernnung_messen(df_url):\n",
    "    r = requests.get(df_url)\n",
    "    try:\n",
    "        json_data = json.loads(r.text)\n",
    "        ergebnis = json_data['features'][0]['properties']['track-length']\n",
    "    except:\n",
    "        ergebnis = 0\n",
    "        pass\n",
    "    \n",
    "    # Pause, um den Server nicht zu überlasten\n",
    "    time.sleep(2)\n",
    "    return (ergebnis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion auf ganzen Dataframe anwenden\n",
    "df['distance'] = df['url'].apply(entfernnung_messen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ergebnis in Zahl umwandeln und in Kilometern ausgeben\n",
    "df['distance'] = pd.to_numeric(df['distance'])\n",
    "df['distance'] = df['distance'] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ist die Zugstrecke Hin- und Rückfahrt? Dann doppelte Distanz\n",
    "\n",
    "df['distance_complete'] = np.where(df['rueckfahrt_gleich'] == True,\n",
    "                                           df['distance'] * 2,\n",
    "                                           df['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distanz ausrechnen\n",
    "\n",
    "summe = df.distance_complete.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Sie sind', round(summe,0), 'Kilometer mit der Bahn gefahren')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
